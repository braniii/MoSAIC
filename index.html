<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>mosaic API documentation</title>
<meta name="description" content="&lt;div align=&#34;center&#34;&gt;
&lt;img class=&#34;darkmode&#34; style=&#34;width: 400px;&#34; …" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.0/styles/atom-one-dark.min.css" rel="stylesheet">
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#282c34;-webkit-border-radius:6px;-moz-border-radius:6px;border-radius:6px;margin:1em 0;padding:1ex}#lunr-search{width:100%;font-size:1em;padding:6px 9px 5px 9px;border:1px solid silver;margin-top:10px;-webkit-border-radius:6px;-moz-border-radius:6px;border-radius:6px}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em;-webkit-border-radius:6px;-moz-border-radius:6px;border-radius:6px}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML'></script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:#555;padding-bottom:.5em;border-bottom:1px solid silver}.homelink:hover{color:inherit}.homelink img{max-width:100%;max-height:5em;margin:auto;margin-bottom:.3em}.darkmode{display:none !important}</style>
<link rel="icon" href="icon.png">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>mosaic</code></h1>
</header>
<section id="section-intro">
<div align="center">
<img class="darkmode" style="width: 400px;" src="https://github.com/moldyn/MoSAIC/blob/main/docs/logo_large_dark.svg?raw=true#gh-dark-mode-only" />
<img class="lightmode" style="width: 400px;" src="https://github.com/moldyn/MoSAIC/blob/main/docs/logo_large_light.svg?raw=true#gh-light-mode-only" />
<p>
<a href="https://github.com/wemake-services/wemake-python-styleguide" alt="wemake-python-styleguide">
<img src="https://img.shields.io/badge/style-wemake-000000.svg" /></a>
<a href="https://beartype.rtfd.io" alt="bear-ified">
<img src="https://raw.githubusercontent.com/beartype/beartype-assets/main/badge/bear-ified.svg" /></a>
<a href="https://pypi.org/project/mosaic-clustering" alt="PyPI">
<img src="https://img.shields.io/pypi/v/mosaic-clustering" /></a>
<a href="https://anaconda.org/conda-forge/mosaic-clustering" alt="conda version">
<img src="https://img.shields.io/conda/vn/conda-forge/mosaic-clustering" /></a>
<a href="https://pepy.tech/project/mosaic-clustering" alt="Downloads">
<img src="https://pepy.tech/badge/mosaic-clustering" /></a>
<a href="https://github.com/moldyn/MoSAIC/actions/workflows/pytest.yml" alt="GitHub Workflow Status">
<img src="https://img.shields.io/github/workflow/status/moldyn/MoSAIC/Pytest"></a>
<a href="https://codecov.io/gh/moldyn/MoSAIC" alt="Code coverage">
<img src="https://codecov.io/gh/moldyn/MoSAIC/branch/main/graph/badge.svg?token=KNWDAUXIGI" /></a>
<a href="https://lgtm.com/projects/g/moldyn/MoSAIC" alt="Code coverage">
<img src="https://img.shields.io/lgtm/grade/python/github/moldyn/MoSAIC" alt="LGTM Grade" /></a>
<a href="https://img.shields.io/pypi/pyversions/mosaic-clustering" alt="PyPI - Python Version">
<img src="https://img.shields.io/pypi/pyversions/mosaic-clustering" /></a>
<a href="https://moldyn.github.io/MoSAIC" alt="Docs">
<img src="https://img.shields.io/badge/pdoc3-Documentation-brightgreen" /></a>
<a href="https://doi.org/10.1021/acs.jctc.2c00337" alt="doi">
<img src="https://img.shields.io/badge/doi-10.1021%2Facs.jctc.2c00337-blue" /></a>
<a href="https://arxiv.org/abs/2204.02770" alt="arXiv">
<img src="https://img.shields.io/badge/arXiv-2204.02770-red" /></a>
<a href="https://github.com/moldyn/MoSAIC/blob/main/LICENSE" alt="License">
<img src="https://img.shields.io/github/license/moldyn/MoSAIC" /></a>
</p>
<p>
<a href="https://moldyn.github.io/MoSAIC">Docs</a> •
<a href="#features">Features</a> •
<a href="#installation">Installation</a> •
<a href="#usage">Usage</a> •
<a href="#faq">FAQ</a>
</p>
</div>
<h1 id="molecular-systems-automated-identification-of-cooperativity">Molecular Systems Automated Identification of Cooperativity</h1>
<p>MoSAIC is a new method for correlation analysis which automatically detects
collective motion in MD simulation data, identifies uncorrelated features as
noise and hence provides a detailed picture of the key coordinates driving a
conformational change in a biomolecular system. It is based on the Leiden
community detection algorithm which is used to bring a correlation matrix in a
block-diagonal form.</p>
<p>The method was published in:</p>
<blockquote>
<p>G. Diez, D. Nagel, and G. Stock,
<em>Correlation-Based Feature Selection to Identify Functional Dynamcis
in Proteins</em>, J. Chem. Theory Comput., 2022, XXXX, XXX, XXX-XXX,
<a href="https://pubs.acs.org/doi/10.1021/acs.jctc.2c00337">10.1021/acs.jctc.2c00337</a></p>
</blockquote>
<p>We kindly ask you to cite this article in case you use this software package
for published works.</p>
<h2 id="features">Features</h2>
<ul>
<li>Intuitive usage via <a href="#module---inside-a-python-script">module</a> and via
<a href="#ci---usage-directly-from-the-command-line">CI</a></li>
<li>Sklearn-style API for fast integration into your Python workflow</li>
<li>No magic, only a
single parameter which can be optimized via
cross-validation</li>
<li>Extensive <a href="https://moldyn.github.io/MoSAIC">documentation</a> and
detailed discussion in publication</li>
</ul>
<h2 id="installation">Installation</h2>
<p>The package is called <code>mosaic-clustering</code> and is available via
<a href="https://pypi.org/project/mosaic-clustering">PyPI</a> or
<a href="https://anaconda.org/conda-forge/mosaic-clustering">conda</a>. To install it,
simply call:</p>
<pre><code class="language-bash">python3 -m pip install --upgrade mosaic-clustering
</code></pre>
<p>or</p>
<pre><code>conda install -c conda-forge mosaic-clustering
</code></pre>
<p>or for the latest dev version</p>
<pre><code class="language-bash"># via ssh key
python3 -m pip install git+ssh://git@github.com/moldyn/MoSAIC.git

# or via password-based login
python3 -m pip install git+https://github.com/moldyn/MoSAIC.git
</code></pre>
<p>In case one wants to use the deprecated <code><a title="mosaic.UMAPSimilarity" href="#mosaic.UMAPSimilarity">UMAPSimilarity</a></code> or the module
<code><a title="mosaic" href="#mosaic">mosaic</a> umap</code> one needs to specify the <code>extras_require='umap'</code>, so</p>
<pre><code class="language-bash">python3 -m pip install --upgrade moldyn-mosaic[umap]
</code></pre>
<h3 id="shell-completion">Shell Completion</h3>
<p>Using the <code>bash</code>, <code>zsh</code> or <code>fish</code> shell click provides an easy way to
provide shell completion, checkout the
<a href="https://click.palletsprojects.com/en/8.0.x/shell-completion">docs</a>.
In the case of bash you need to add following line to your <code>~/.bashrc</code></p>
<pre><code class="language-bash">eval &quot;$(_MOSAIC_COMPLETE=bash_source mosaic)&quot;
</code></pre>
<h2 id="usage">Usage</h2>
<p>In general one can call the module directly by its entry point <code>$ MoSAIC</code>
or by calling the module <code>$ python -m mosaic</code>. The latter method is
preferred to ensure using the desired python environment. For enabling
the shell completion, the entry point needs to be used.</p>
<h3 id="ci-usage-directly-from-the-command-line">CI - Usage Directly from the Command Line</h3>
<p>The module brings a rich CI using <a href="https://click.palletsprojects.com">click</a>.
Each module and submodule contains a detailed help, which can be accessed by</p>
<pre><code class="language-bash">$ python -m mosaic
Usage: python -m mosaic [OPTIONS] COMMAND [ARGS]...

  MoSAIC motion v0.2.2

  Molecular systems automated identification of collective motion, is
  a correlation based feature selection framework for MD data.
  Copyright (c) 2021-2022, Georg Diez and Daniel Nagel

Options:
  --help  Show this message and exit.

Commands:
  clustering  Clustering similarity matrix of coordinates.
  similarity  Creating similarity matrix of coordinates.
  umap        Embedd similarity matrix with UMAP.
</code></pre>
<p>For more details on the submodule one needs to specify one of the three
commands.</p>
<p>A simple workflow example for clustering the input file <code>input_file</code> using
correlation and Leiden with CPM and the default resolution parameter:</p>
<pre><code class="language-bash"># creating correlation matrix
$ python -m mosaic similarity -i input_file -o output_similarity -metric correlation -v

MoSAIC SIMILARITY
~~~ Initialize similarity class
~~~ Load file input_file
~~~ Fit input
~~~ Store similarity matrix in output_similarity

# clustering with CPM and default resolution parameter
# the latter needs to be fine-tuned to each matrix
$ python -m mosaic clustering -i output_similarity -o output_clustering --plot -v

MoSAIC CLUSTERING
~~~ Initialize clustering class
~~~ Load file output_similarity
~~~ Fit input
~~~ Store output
~~~ Plot matrix
</code></pre>
<p>This will generate the similarity matrix stored in <code>output_similarity</code>,
the plotted result in <code>output_clustering.matrix.pdf</code>, the raw data of
the matrix in <code>output_clustering.matrix</code> and a file containing in each
row the indices of a cluster.</p>
<h3 id="module-inside-a-python-script">Module - Inside a Python Script</h3>
<pre><code class="language-python">import mosaic

# Load file
# X is np.ndarray of shape (n_samples, n_features)

sim = mosaic.Similarity(
    metric='correlation',  # or 'NMI', 'GY', 'JSD'
)
sim.fit(X)


# Cluster matrix
clust = mosaic.Clustering(
    mode='CPM',  # or 'modularity
)
clust.fit(sim.matrix_)

clusters = clust.clusters_
clusterd_X = clust.matrix_
...
</code></pre>
<h3 id="cross-validation-of-parameters">Cross-Validation of Parameters</h3>
<p>Selecting the optimal parameters, e.g., <code>resolution_parameter</code>, or
<code>n_clusters</code>, can be quite difficult. Here we show a short example how one can
use cross-validation for optimizing the parameters. Nevertheless, one should
keep in mind that the here used silhouette score is not optimal for our task.
Hence, the here obtained optimal parameters should be considered as a good
first guess.</p>
<p>Here a figure visualizing the optimal cluster value <code>n_clusters=12</code> and the
code to produce it.</p>
<p><img class="lightmode" style="width: 400px;" src="https://github.com/moldyn/MoSAIC/blob/main/docs/cv_silhouette_light.svg?raw=true#gh-light-mode-only" /><img class="darkmode" style="width: 400px;" src="https://github.com/moldyn/MoSAIC/blob/main/docs/cv_silhouette_dark.svg?raw=true#gh-dark-mode-only" /></p>
<pre><code class="language-python">import mosaic
import numpy as np
import prettypyplot as pplt
from matplotlib import pyplot as plt

pplt.use_style(colors='tab20c', figsize=2.4)

# traj = np.loadtxt(filename)

# specify parameters grid
n_clusters = np.arange(2, traj.shape[1])
params = {'n_clusters': n_clusters}
search = mosaic.GridSearchCV(
    similarity=mosaic.Similarity(),
    clustering=mosaic.Clustering(
        mode='kmedoids',
        n_clusters=2,  # any dummy value is good here
    ),
    param_grid=params,
).fit(traj)

# plotting result
fig, ax = plt.subplots()
mean_score = search.cv_results_['mean_test_score']
std_score = search.cv_results_['std_test_score']

ax.fill_between(
    n_clusters,
    mean_score + std_score,
    mean_score - std_score,
    color='C2',
)
ax.plot(n_clusters, mean_score + std_score, c='C1')
ax.plot(n_clusters, mean_score - std_score, c='C1')
ax.plot(n_clusters, mean_score, c='C0')

ax.set_xlim([0, traj.shape[1]])
ax.set_xlabel(r'$k$ no. of clusters')
ax.set_ylabel(r'silhouette score')

pplt.savefig('cv_silhouette.pdf')
</code></pre>
<h3 id="faq">FAQ</h3>
<h4 id="how-to-load-the-clusters-file-back-to-python">How to load the clusters file back to Python?</h4>
<p>Simply use the function provided in <code>tools</code>:</p>
<pre><code class="language-python">import mosaic

clusterfile = '...'
clusters = mosaic.tools.load_clusters(clusterfile)
</code></pre>
<h4 id="is-it-possible-to-use-cross-validation-together-with-silhouette-score">Is it possible to use cross validation together with silhouette score?</h4>
<p>The new release <code>v0.3.0</code> refactored the classes, so that the
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"><code>sklearn.model_selection.GridSearchCV</code></a>
can be used. Check out the <a href="#cross-validation-of-parameters">cv example</a>.</p>
<h4 id="i-get-an-error">I get an error.</h4>
<p>Please <a href="https://github.com/moldyn/MoSAIC/issues/new/choose">open an issue</a>.</p>
<h4 id="should-i-upgrade-the-package">Should I upgrade the package?</h4>
<p>You can check out the CHANGELOG.md to see what changed.</p>
<h4 id="how-can-i-interpretate-the-results">How can I interpretate the results?</h4>
<p>Check out our publication for two detailed examples.</p>
<h4 id="is-it-possible-to-install-the-cli-only">Is it possible to install the CLI only?</h4>
<p>Partially, yes. If you do not want to screw up your current Python
environment there are multiples possibilities. Either create a
virtual environment on your own via <code>conda</code> or <code>venv</code>, or you can
simply use <a href="https://pypa.github.io/pipx/">pipx</a></p>
<h4 id="is-the-silhouette-method-implemented">Is the silhouette method implemented?</h4>
<p>Yes, simply use the <code>score</code> method implemented in the <code><a title="mosaic.Clustering" href="#mosaic.Clustering">Clustering</a></code> class.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;.. include:: ../../README.md&#34;&#34;&#34;
__all__ = [&#39;Clustering&#39;, &#39;GridSearchCV&#39;, &#39;Similarity&#39;, &#39;UMAPSimilarity&#39;]

import mosaic.utils  # noqa: F401
from .clustering import Clustering
from .gridsearch import GridSearchCV
from .similarity import Similarity
from .umap_similarity import UMAPSimilarity


__version__ = &#39;0.3.0&#39;</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="mosaic.clustering" href="clustering.html">mosaic.clustering</a></code></dt>
<dd>
<div class="desc"><p>Class for clustering the correlation matrices …</p></div>
</dd>
<dt><code class="name"><a title="mosaic.gridsearch" href="gridsearch.html">mosaic.gridsearch</a></code></dt>
<dd>
<div class="desc"><p>Class for GridSearchCV with silhouette score …</p></div>
</dd>
<dt><code class="name"><a title="mosaic.similarity" href="similarity.html">mosaic.similarity</a></code></dt>
<dd>
<div class="desc"><p>Class for estimating correlation matrices …</p></div>
</dd>
<dt><code class="name"><a title="mosaic.umap_similarity" href="umap_similarity.html">mosaic.umap_similarity</a></code></dt>
<dd>
<div class="desc"><p>Class for embedding correlation matrix with UMAP …</p></div>
</dd>
<dt><code class="name"><a title="mosaic.utils" href="utils.html">mosaic.utils</a></code></dt>
<dd>
<div class="desc"><p>Class with helper functions …</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="mosaic.Clustering"><code class="flex name class">
<span>class <span class="ident">Clustering</span></span>
<span>(</span><span>*, mode='CPM', weighted=True, n_neighbors=None, resolution_parameter=None, n_clusters=None, seed=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for clustering a correlation matrix.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>mode</code></strong> :&ensp;<code>str</code>, default=<code>'CPM'</code></dt>
<dd>the mode which determines the quality function optimized by the Leiden
algorithm ('CPM', or 'modularity') or linkage clustering.
- 'CPM': will use the constant Potts model on the full, weighted graph
- 'modularity': will use modularity on a knn-graph
- 'linkage': will use complete-linkage clustering
- 'kmedoids': will use k-medoids clustering</dd>
<dt><strong><code>weighted</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>If True, the underlying graph has weighted edges. Otherwise, the graph
is constructed using the adjacency matrix.</dd>
<dt><strong><code>n_neighbors</code></strong> :&ensp;<code>int</code>, default=<code>None</code></dt>
<dd>This parameter specifies whether the whole matrix should be used, or
a knn-graph, which reduces the required memory.
The default depends on the <code>mode</code>
- 'CPM': <code>None</code> uses the full graph, and
- 'modularity': <code>None</code> uses square root of the number of features.</dd>
<dt><strong><code>resolution_parameter</code></strong> :&ensp;<code>float</code>, default=<code>None</code></dt>
<dd>Required for mode 'CPM' and 'linkage'. If None, the resolution
parameter will be set to the third quartile of <code>X</code> for
<code>n_neighbors=None</code> and else to the mean value of the knn graph.</dd>
<dt><strong><code>n_clusters</code></strong> :&ensp;<code>int</code>, default=<code>None</code></dt>
<dd>Required for 'kmedoids'. The number of medoids which will constitute
the later clusters.</dd>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code>, default=<code>None</code></dt>
<dd>Use an integer to make the randomness of Leidenalg deterministic. By
default uses a random seed if nothing is specified.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>clusters_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_clusters, )</code></dt>
<dd>The result of the clustering process. A list of arrays, each
containing all indices (features) corresponging to each cluster.</dd>
<dt><strong><code>labels_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features, )</code></dt>
<dd>Labels of each feature.</dd>
<dt><strong><code>matrix_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features, n_features)</code></dt>
<dd>Permuted matrix according to the determined clusters.</dd>
<dt><strong><code>ticks_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_clusters, )</code></dt>
<dd>The cumulative number of features containing to the clusters.
May be used as ticks for plotting <code>matrix_</code>.</dd>
<dt><strong><code>permutation_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features, )</code></dt>
<dd>Permutation of the input features (corresponds to flattened
<code>clusters_</code>).</dd>
<dt><strong><code>n_neighbors_</code></strong> :&ensp;<code>int</code></dt>
<dd>Only avaiable when using knn graph. Indicates the number of nearest
neighbors used for constructin the knn-graph.</dd>
<dt><strong><code>resolution_param_</code></strong> :&ensp;<code>float</code></dt>
<dd>Only for mode 'CPM' and 'linkage'. Indicates the resolution parameter
used for the CPM based Leiden clustering.</dd>
<dt><strong><code>linkage_matrix_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_clusters - 1, 4)</code></dt>
<dd>Only for mode 'linkage'. Contains the hierarchical clustering encoded
as a linkage matrix, see
<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html">scipy:spatial.distance.linkage</a>.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import mosaic
&gt;&gt;&gt; mat = np.array([[1.0, 0.1, 0.9], [0.1, 1.0, 0.1], [0.9, 0.1, 1.0]])
&gt;&gt;&gt; clust = mosaic.Clustering()
&gt;&gt;&gt; clust.fit(mat)
Clustering(resolution_parameter=0.7)
&gt;&gt;&gt; clust.matrix_
array([[1. , 0.9, 0.1],
       [0.9, 1. , 0.1],
       [0.1, 0.1, 1. ]])
&gt;&gt;&gt; clust.clusters_
array([list([2, 0]), list([1])], dtype=object)
</code></pre>
<p>Initialize Clustering class.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Clustering(ClusterMixin, BaseEstimator):
    r&#34;&#34;&#34;Class for clustering a correlation matrix.

    Parameters
    ----------
    mode : str, default=&#39;CPM&#39;
        the mode which determines the quality function optimized by the Leiden
        algorithm (&#39;CPM&#39;, or &#39;modularity&#39;) or linkage clustering.
        - &#39;CPM&#39;: will use the constant Potts model on the full, weighted graph
        - &#39;modularity&#39;: will use modularity on a knn-graph
        - &#39;linkage&#39;: will use complete-linkage clustering
        - &#39;kmedoids&#39;: will use k-medoids clustering

    weighted : bool, default=True
        If True, the underlying graph has weighted edges. Otherwise, the graph
        is constructed using the adjacency matrix.

    n_neighbors : int, default=None
        This parameter specifies whether the whole matrix should be used, or
        a knn-graph, which reduces the required memory.
        The default depends on the `mode`
        - &#39;CPM&#39;: `None` uses the full graph, and
        - &#39;modularity&#39;: `None` uses square root of the number of features.

    resolution_parameter : float, default=None
        Required for mode &#39;CPM&#39; and &#39;linkage&#39;. If None, the resolution
        parameter will be set to the third quartile of `X` for
        `n_neighbors=None` and else to the mean value of the knn graph.

    n_clusters : int, default=None
        Required for &#39;kmedoids&#39;. The number of medoids which will constitute
        the later clusters.

    seed : int, default=None
        Use an integer to make the randomness of Leidenalg deterministic. By
        default uses a random seed if nothing is specified.

    Attributes
    ----------
    clusters_ : ndarray of shape (n_clusters, )
        The result of the clustering process. A list of arrays, each
        containing all indices (features) corresponging to each cluster.

    labels_ : ndarray of shape (n_features, )
        Labels of each feature.

    matrix_ : ndarray of shape (n_features, n_features)
        Permuted matrix according to the determined clusters.

    ticks_ : ndarray of shape (n_clusters, )
        The cumulative number of features containing to the clusters.
        May be used as ticks for plotting `matrix_`.

    permutation_ : ndarray of shape (n_features, )
        Permutation of the input features (corresponds to flattened
        `clusters_`).

    n_neighbors_ : int
        Only avaiable when using knn graph. Indicates the number of nearest
        neighbors used for constructin the knn-graph.

    resolution_param_ : float
        Only for mode &#39;CPM&#39; and &#39;linkage&#39;. Indicates the resolution parameter
        used for the CPM based Leiden clustering.

    linkage_matrix_ : ndarray of shape (n_clusters - 1, 4)
        Only for mode &#39;linkage&#39;. Contains the hierarchical clustering encoded
        as a linkage matrix, see
        [scipy:spatial.distance.linkage](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html).

    Examples
    --------
    &gt;&gt;&gt; import mosaic
    &gt;&gt;&gt; mat = np.array([[1.0, 0.1, 0.9], [0.1, 1.0, 0.1], [0.9, 0.1, 1.0]])
    &gt;&gt;&gt; clust = mosaic.Clustering()
    &gt;&gt;&gt; clust.fit(mat)
    Clustering(resolution_parameter=0.7)
    &gt;&gt;&gt; clust.matrix_
    array([[1. , 0.9, 0.1],
           [0.9, 1. , 0.1],
           [0.1, 0.1, 1. ]])
    &gt;&gt;&gt; clust.clusters_
    array([list([2, 0]), list([1])], dtype=object)

    &#34;&#34;&#34;

    @beartype
    def __init__(
        self,
        *,
        mode: ClusteringModeString = &#39;CPM&#39;,
        weighted: bool = True,
        n_neighbors: Optional[PositiveInt] = None,
        resolution_parameter: Optional[NumInRange0to1] = None,
        n_clusters: Optional[PositiveInt] = None,
        seed: Optional[int] = None,
    ) -&gt; None:
        &#34;&#34;&#34;Initialize Clustering class.&#34;&#34;&#34;
        self.mode: ClusteringModeString = mode
        self.n_clusters: Optional[PositiveInt] = n_clusters
        self.n_neighbors: Optional[PositiveInt] = n_neighbors
        self.resolution_parameter: Optional[NumInRange0to1] = (
            resolution_parameter
        )
        self.seed: Optional[int] = seed
        self.weighted: bool = weighted

        if mode in {&#39;linkage&#39;, &#39;kmedoids&#39;} and self.n_neighbors is not None:
            raise NotImplementedError(
                f&#34;mode=&#39;{mode}&#39; does not support knn-graphs.&#34;,
            )

        if mode == &#39;kmedoids&#39; and self.n_clusters is None:
            raise TypeError(
                f&#34;mode=&#39;{mode}&#39; needs parameter &#39;n_clusters&#39;&#34;,
            )
        elif mode != &#39;kmedoids&#39; and self.n_clusters is not None:
            raise NotImplementedError(
                f&#34;mode=&#39;{mode}&#39; does not support the usage of &#39;n_clusters&#39;&#34;,
            )

        if mode in {&#39;CPM&#39;, &#39;linkage&#39;}:
            if not weighted:
                raise NotImplementedError(
                    f&#34;mode=&#39;{mode}&#39; does not support weighted=False&#34;,
                )
        elif resolution_parameter is not None:
            raise NotImplementedError(
                f&#34;mode=&#39;{mode}&#39; does not support the usage of the &#34;
                &#39;resolution_parameter&#39;,
            )

    @beartype
    def fit(self, X: SimilarityMatrix, y: Optional[np.ndarray] = None):
        &#34;&#34;&#34;Clusters the correlation matrix by Leiden clustering on a graph.

        Parameters
        ----------
        X : ndarray of shape (n_features, n_features)
            Matrix containing the correlation metric which is clustered. The
            values should go from [0, 1] where 1 means completely correlated
            and 0 no correlation.

        y : Ignored
            Not used, present for scikit API consistency by convention.

        Returns
        -------
        self : object
            Fitted estimator.

        &#34;&#34;&#34;
        self._reset()

        # prepare matric for graph construction
        mat: FloatMatrix
        if self.mode in {&#39;linkage&#39;, &#39;kmedoids&#39;}:
            mat = np.copy(X)
        elif self.mode == &#39;CPM&#39; and self.n_neighbors is None:
            mat = np.copy(X)
        else:
            mat = self._construct_knn_mat(X)

        if self.mode in {&#39;CPM&#39;, &#39;linkage&#39;}:
            # mask diagonal and zero elements
            mat[mat == 0] = np.nan
            mat[np.diag_indices_from(mat)] = np.nan

            if self.resolution_parameter is None:
                if self.n_neighbors is None:
                    third_quartile = 0.75
                    self.resolution_parameter = np.nanquantile(
                        mat, third_quartile,
                    )
                else:
                    self.resolution_parameter = np.nanmean(mat)

            self.resolution_param_: NumInRange0to1 = (
                self.resolution_parameter
            )

        # create graph
        mat[np.isnan(mat)] = 0

        clusters: Object1DArray
        if self.mode == &#39;linkage&#39;:
            clusters = self._clustering_linkage(mat)
        elif self.mode == &#39;kmedoids&#39;:
            clusters = self._clustering_kmedoids(mat)
        else:  # _mode in {&#39;CPM&#39;, &#39;modularity&#39;}
            graph: ig.Graph = ig.Graph.Weighted_Adjacency(
                list(mat.astype(np.float64)), loops=False,
            )
            clusters = self._clustering_leiden(graph)

        self.clusters_: Object1DArray = _sort_clusters(clusters, X)
        self.permutation_: Index1DArray = np.hstack(self.clusters_)
        self.matrix_: Float2DArray = np.copy(X)[
            np.ix_(self.permutation_, self.permutation_)
        ]
        self.ticks_: Index1DArray = np.cumsum(
            [len(cluster) for cluster in self.clusters_],
        )
        labels: Index1DArray = np.empty_like(self.permutation_)
        for idx, cluster in enumerate(self.clusters_):
            labels[cluster] = idx
        self.labels_: Index1DArray = labels

        return self

    @beartype
    def fit_predict(
        self, X: SimilarityMatrix, y: Optional[np.ndarray] = None,
    ) -&gt; Index1DArray:
        &#34;&#34;&#34;Clusters the correlation matrix by Leiden clustering on a graph.

        Parameters
        ----------
        X : ndarray of shape (n_features, n_features)
            Matrix containing the correlation metric which is clustered. The
            values should go from [0, 1] where 1 means completely correlated
            and 0 no correlation.

        y : Ignored
            Not used, present for scikit API consistency by convention.

        Returns
        -------
        labels : ndarray of shape (n_samples,)
            Cluster labels.

        &#34;&#34;&#34;
        return super().fit_predict(X, y)

    @beartype
    def score(
        self,
        X: SimilarityMatrix,
        y: Optional[np.ndarray] = None,
        sample_weight: Optional[np.ndarray] = None,
    ) -&gt; Float:
        &#34;&#34;&#34;Estimate silhouette_score of new correlation matrix.

        Parameters
        ----------
        X : ndarray of shape (n_features, n_features)
            New matrix containing the correlation metric to score. The
            values should go from [0, 1] where 1 means completely correlated
            and 0 no correlation.

        y : Ignored
            Not used, present for scikit API consistency by convention.

        sample_weight: Ignored
            Not used, present for scikit API consistency by convention.

        Returns
        -------
        score : float
            Silhouette score of new correlation matrix based on fitted labels.

        &#34;&#34;&#34;
        check_is_fitted(self, attributes=[&#39;labels_&#39;, &#39;matrix_&#39;])

        n_labels = len(self.labels_)
        n_unique_labels = len(np.unique(self.labels_))

        if n_labels != len(X):
            raise ValueError(
                f&#39;Dimension of X d={len(X):.0f} needs to agree with the &#39;
                f&#39;dimension of the fitted data d={n_labels:.0f}.&#39;,
            )

        if n_unique_labels in {1, n_labels}:
            return -1.0
        return silhouette_score(X, labels=self.labels_)

    @beartype
    def _reset(self) -&gt; None:
        &#34;&#34;&#34;Reset internal data-dependent state of correlation.&#34;&#34;&#34;
        if hasattr(self, &#39;clusters_&#39;):  # noqa: WPS421
            del self.clusters_  # noqa: WPS420
            del self.labels_  # noqa: WPS420
            del self.ticks_  # noqa: WPS420
            del self.permutation_  # noqa: WPS420
            del self.matrix_  # noqa: WPS420

        if hasattr(self, &#39;linkage_matrix_&#39;):  # noqa: WPS421
            del self.linkage_matrix_  # noqa: WPS420
        if hasattr(self, &#39;n_neighbors_&#39;):  # noqa: WPS421
            del self.n_neighbors_  # noqa: WPS420
        if hasattr(self, &#39;resolution_param_&#39;):  # noqa: WPS421
            del self.resolution_param_  # noqa: WPS420
        if hasattr(self, &#39;n_clusters_&#39;):  # noqa: WPS421
            del self.n_clusters_  # noqa: WPS420

    @beartype
    def _construct_knn_mat(self, matrix: FloatMatrix) -&gt; FloatMatrix:
        &#34;&#34;&#34;Construct the knn matrix.&#34;&#34;&#34;
        if self.n_neighbors is None:
            n_features = len(matrix)
            self.n_neighbors = np.ceil(np.sqrt(n_features)).astype(int)
        elif self.n_neighbors &gt;= len(matrix):
            raise ValueError(
                &#39;The number of nearest neighbors must be smaller than the &#39;
                &#39;number of features.&#39;,
            )
        self.n_neighbors_: PositiveInt = self.n_neighbors

        neigh = NearestNeighbors(
            n_neighbors=self.n_neighbors,
            metric=&#39;precomputed&#39;,
        )
        neigh.fit(1 - matrix)
        if self.weighted:
            dist_mat = neigh.kneighbors_graph(mode=&#39;distance&#39;).toarray()
            dist_mat[dist_mat == 0] = 1
            return 1 - dist_mat
        return neigh.kneighbors_graph(mode=&#39;connectivity&#39;).toarray()

    @beartype
    def _setup_leiden_kwargs(self, graph: ig.Graph) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Set up the parameters for the Leiden clustering.&#34;&#34;&#34;
        kwargs_leiden = {&#39;n_iterations&#39;: -1}
        if self.mode == &#39;CPM&#39;:
            kwargs_leiden[&#39;partition_type&#39;] = la.CPMVertexPartition
            kwargs_leiden[
                &#39;resolution_parameter&#39;
            ] = self.resolution_param_
        else:
            kwargs_leiden[
                &#39;partition_type&#39;
            ] = la.ModularityVertexPartition
        if self.weighted:
            kwargs_leiden[&#39;weights&#39;] = graph.es[&#39;weight&#39;]

        kwargs_leiden[&#39;seed&#39;] = self.seed

        return kwargs_leiden

    @beartype
    def _clustering_leiden(self, graph: ig.Graph) -&gt; Object1DArray:
        &#34;&#34;&#34;Perform the Leiden clustering on the graph.&#34;&#34;&#34;
        clusters = la.find_partition(
            graph, **self._setup_leiden_kwargs(graph),
        )
        # In case of clusters of same length, numpy casted it as a 2D array.
        # To ensure that the result is an numpy array of list, we need to
        # create an empty list, adding the values in the second step
        cluster_list: Object1DArray = np.empty(len(clusters), dtype=object)
        cluster_list[:] = clusters  # noqa: WPS362
        return cluster_list

    @beartype
    def _clustering_linkage(self, matrix: FloatMatrix) -&gt; Object1DArray:
        &#34;&#34;&#34;Perform the linkage clustering.&#34;&#34;&#34;
        matrix[np.diag_indices_from(matrix)] = 1
        linkage_matrix: Float2DArray = linkage(
            squareform(1 - matrix),
            method=&#39;complete&#39;,
            optimal_ordering=True,
        )
        # store linkage tree
        self.linkage_matrix_: Float2DArray = linkage_matrix

        cuttree: Index1DArray = cut_tree(
            linkage_matrix, height=1 - self.resolution_param_,
        ).flatten()

        # In case of clusters of same length, numpy casted it as a 2D array.
        # To ensure that the result is an numpy array of list, we need to
        # create an empty list, adding the values in the second step
        nclusters: int = len(np.unique(cuttree))
        cluster_list: Object1DArray = np.empty(nclusters, dtype=object)
        cluster_list[:] = [  # noqa: WPS362
            np.where(cuttree == cluster)[0].tolist()
            for cluster in np.unique(cuttree)
        ]
        return cluster_list

    @beartype
    def _clustering_kmedoids(self, matrix: FloatMatrix) -&gt; Object1DArray:
        &#34;&#34;&#34;Perform k-medoids clustering.&#34;&#34;&#34;
        kmedoids_kwargs = {
            &#39;metric&#39;: &#39;precomputed&#39;,
            &#39;max_iter&#39;: 100000,
            &#39;method&#39;: &#39;pam&#39;,
        }

        kmedoids = KMedoids(n_clusters=self.n_clusters, **kmedoids_kwargs)
        kmedoids.fit(1 - matrix)
        labels = kmedoids.labels_

        # store number of clusters
        nclusters: int = len(np.unique(labels))
        if nclusters != self.n_clusters:
            raise ValueError(
                f&#39;k-medoids tried to find {self.n_clusters} clusters&#39;
                f&#39;but only {nclusters} found. Please try a different value.&#39;,
            )
        self.n_clusters_: Float2DArray = nclusters

        # In case of clusters of same length, numpy casted it as a 2D array.
        # To ensure that the result is an numpy array of list, we need to
        # create an empty list, adding the values in the second step
        cluster_list: Object1DArray = np.empty(nclusters, dtype=object)
        cluster_list[:] = [  # noqa: WPS362
            np.where(labels == label)[0].tolist()
            for label in np.unique(labels)
        ]
        return cluster_list</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.base.ClusterMixin</li>
<li>sklearn.base.BaseEstimator</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mosaic.Clustering.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, X, y=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Clusters the correlation matrix by Leiden clustering on a graph.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features, n_features)</code></dt>
<dd>Matrix containing the correlation metric which is clustered. The
values should go from [0, 1] where 1 means completely correlated
and 0 no correlation.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>Ignored</code></dt>
<dd>Not used, present for scikit API consistency by convention.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>self</code></strong> :&ensp;<code>object</code></dt>
<dd>Fitted estimator.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def fit(self, X: SimilarityMatrix, y: Optional[np.ndarray] = None):
    &#34;&#34;&#34;Clusters the correlation matrix by Leiden clustering on a graph.

    Parameters
    ----------
    X : ndarray of shape (n_features, n_features)
        Matrix containing the correlation metric which is clustered. The
        values should go from [0, 1] where 1 means completely correlated
        and 0 no correlation.

    y : Ignored
        Not used, present for scikit API consistency by convention.

    Returns
    -------
    self : object
        Fitted estimator.

    &#34;&#34;&#34;
    self._reset()

    # prepare matric for graph construction
    mat: FloatMatrix
    if self.mode in {&#39;linkage&#39;, &#39;kmedoids&#39;}:
        mat = np.copy(X)
    elif self.mode == &#39;CPM&#39; and self.n_neighbors is None:
        mat = np.copy(X)
    else:
        mat = self._construct_knn_mat(X)

    if self.mode in {&#39;CPM&#39;, &#39;linkage&#39;}:
        # mask diagonal and zero elements
        mat[mat == 0] = np.nan
        mat[np.diag_indices_from(mat)] = np.nan

        if self.resolution_parameter is None:
            if self.n_neighbors is None:
                third_quartile = 0.75
                self.resolution_parameter = np.nanquantile(
                    mat, third_quartile,
                )
            else:
                self.resolution_parameter = np.nanmean(mat)

        self.resolution_param_: NumInRange0to1 = (
            self.resolution_parameter
        )

    # create graph
    mat[np.isnan(mat)] = 0

    clusters: Object1DArray
    if self.mode == &#39;linkage&#39;:
        clusters = self._clustering_linkage(mat)
    elif self.mode == &#39;kmedoids&#39;:
        clusters = self._clustering_kmedoids(mat)
    else:  # _mode in {&#39;CPM&#39;, &#39;modularity&#39;}
        graph: ig.Graph = ig.Graph.Weighted_Adjacency(
            list(mat.astype(np.float64)), loops=False,
        )
        clusters = self._clustering_leiden(graph)

    self.clusters_: Object1DArray = _sort_clusters(clusters, X)
    self.permutation_: Index1DArray = np.hstack(self.clusters_)
    self.matrix_: Float2DArray = np.copy(X)[
        np.ix_(self.permutation_, self.permutation_)
    ]
    self.ticks_: Index1DArray = np.cumsum(
        [len(cluster) for cluster in self.clusters_],
    )
    labels: Index1DArray = np.empty_like(self.permutation_)
    for idx, cluster in enumerate(self.clusters_):
        labels[cluster] = idx
    self.labels_: Index1DArray = labels

    return self</code></pre>
</details>
</dd>
<dt id="mosaic.Clustering.fit_predict"><code class="name flex">
<span>def <span class="ident">fit_predict</span></span>(<span>self, X, y=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Clusters the correlation matrix by Leiden clustering on a graph.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features, n_features)</code></dt>
<dd>Matrix containing the correlation metric which is clustered. The
values should go from [0, 1] where 1 means completely correlated
and 0 no correlation.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>Ignored</code></dt>
<dd>Not used, present for scikit API consistency by convention.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>labels</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_samples,)</code></dt>
<dd>Cluster labels.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def fit_predict(
    self, X: SimilarityMatrix, y: Optional[np.ndarray] = None,
) -&gt; Index1DArray:
    &#34;&#34;&#34;Clusters the correlation matrix by Leiden clustering on a graph.

    Parameters
    ----------
    X : ndarray of shape (n_features, n_features)
        Matrix containing the correlation metric which is clustered. The
        values should go from [0, 1] where 1 means completely correlated
        and 0 no correlation.

    y : Ignored
        Not used, present for scikit API consistency by convention.

    Returns
    -------
    labels : ndarray of shape (n_samples,)
        Cluster labels.

    &#34;&#34;&#34;
    return super().fit_predict(X, y)</code></pre>
</details>
</dd>
<dt id="mosaic.Clustering.score"><code class="name flex">
<span>def <span class="ident">score</span></span>(<span>self, X, y=None, sample_weight=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Estimate silhouette_score of new correlation matrix.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features, n_features)</code></dt>
<dd>New matrix containing the correlation metric to score. The
values should go from [0, 1] where 1 means completely correlated
and 0 no correlation.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>Ignored</code></dt>
<dd>Not used, present for scikit API consistency by convention.</dd>
<dt><strong><code>sample_weight</code></strong> :&ensp;<code>Ignored</code></dt>
<dd>Not used, present for scikit API consistency by convention.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>score</code></strong> :&ensp;<code>float</code></dt>
<dd>Silhouette score of new correlation matrix based on fitted labels.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def score(
    self,
    X: SimilarityMatrix,
    y: Optional[np.ndarray] = None,
    sample_weight: Optional[np.ndarray] = None,
) -&gt; Float:
    &#34;&#34;&#34;Estimate silhouette_score of new correlation matrix.

    Parameters
    ----------
    X : ndarray of shape (n_features, n_features)
        New matrix containing the correlation metric to score. The
        values should go from [0, 1] where 1 means completely correlated
        and 0 no correlation.

    y : Ignored
        Not used, present for scikit API consistency by convention.

    sample_weight: Ignored
        Not used, present for scikit API consistency by convention.

    Returns
    -------
    score : float
        Silhouette score of new correlation matrix based on fitted labels.

    &#34;&#34;&#34;
    check_is_fitted(self, attributes=[&#39;labels_&#39;, &#39;matrix_&#39;])

    n_labels = len(self.labels_)
    n_unique_labels = len(np.unique(self.labels_))

    if n_labels != len(X):
        raise ValueError(
            f&#39;Dimension of X d={len(X):.0f} needs to agree with the &#39;
            f&#39;dimension of the fitted data d={n_labels:.0f}.&#39;,
        )

    if n_unique_labels in {1, n_labels}:
        return -1.0
    return silhouette_score(X, labels=self.labels_)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mosaic.GridSearchCV"><code class="flex name class">
<span>class <span class="ident">GridSearchCV</span></span>
<span>(</span><span>*, similarity, clustering, param_grid, gridsearch_kwargs={})</span>
</code></dt>
<dd>
<div class="desc"><p>Class for grid searhc cross validation.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>similarity</code></strong> :&ensp;<code><a title="mosaic.Similarity" href="#mosaic.Similarity">Similarity</a></code></dt>
<dd>Similarity instance setup with constant parameters, see
<code><a title="mosaic.Similarity" href="#mosaic.Similarity">Similarity</a></code> for available parameters. <code>low_memory</code> is not
supported.</dd>
<dt><strong><code>clustering</code></strong> :&ensp;<code><a title="mosaic.Clustering" href="#mosaic.Clustering">Clustering</a></code></dt>
<dd>Clustering instance setup with constant parameters, see
<code><a title="mosaic.Clustering" href="#mosaic.Clustering">Clustering</a></code> for available parameters.</dd>
<dt><strong><code>param_grid</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary with parameters names (<code>str</code>) as keys and lists of
parameter settings to try as values, or list of such dictionaries,
in which case the grids spanned by each dictionary in the list are
explored.</dd>
<dt><strong><code>gridsearch_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary with parameters to be used for
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"><code>sklearn.model_selection.GridSearchCV</code></a>
class. The parameter <code>estimator</code> is not supported and <code>param_grid</code>
needs to be passed directly to the class.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>cv_results_</code></strong> :&ensp;<code>dict</code> of <code>numpy (masked) ndarrays</code></dt>
<dd>A dict with keys as column headers and values as columns.</dd>
<dt><strong><code>best_estimator_</code></strong> :&ensp;<code>estimator</code></dt>
<dd>Estimator that was chosen by the search, i.e. estimator
which gave highest score (or smallest loss if specified)
on the left out data.</dd>
<dt><strong><code>best_score_</code></strong> :&ensp;<code>float</code></dt>
<dd>Mean cross-validated score of the best_estimator.</dd>
<dt><strong><code>best_params_</code></strong> :&ensp;<code>dict</code></dt>
<dd>Parameter setting that gave the best results on the hold out data.</dd>
<dt><strong><code>best_index_</code></strong> :&ensp;<code>int</code></dt>
<dd>The index (of the <code>cv_results_</code> arrays) which corresponds to the best
candidate parameter setting.</dd>
<dt><strong><code>n_splits_</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of cross-validation splits (folds/iterations).</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Check out
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html">sklearn.model_selection.GridSearchCV</a>
for an overview of all available attributes and more detailed description.</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import mosaic
&gt;&gt;&gt; # create two correlated data sets
&gt;&gt;&gt; traj = np.array([
...     func(np.linspace(0, 20, 1000))
...     for  func in (
...         np.sin,
...         lambda x: np.sin(x + 0.1),
...         np.cos,
...         lambda x: np.cos(x + 0.1),
...     )
... ]).T
&gt;&gt;&gt; search = mosaic.GridSearchCV(
...     similarity=mosaic.Similarity(),
...     clustering=mosaic.Clustering(),
...     param_grid={'resolution_parameter': [0.05, 0.2]},
... )
&gt;&gt;&gt; search.fit(traj)
GridSearchCV(clustering=Clustering(),
             param_grid={'clust__resolution_parameter': [0.05, 0.2]},
             similarity=Similarity())
&gt;&gt;&gt; search.best_params_
{'clust__resolution_parameter': 0.2}
&gt;&gt;&gt; search.best_estimator_
Pipeline(steps=[('sim', Similarity()),
                ('clust', Clustering(resolution_parameter=0.2))])
</code></pre>
<p>Initialize GridSearchCV class.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GridSearchCV(SKGridSearchCV):
    r&#34;&#34;&#34;Class for grid searhc cross validation.

    Parameters
    ----------
    similarity : mosaic.Similarity
        Similarity instance setup with constant parameters, see
        `mosaic.Similarity` for available parameters. `low_memory` is not
        supported.

    clustering : mosaic.Clustering
        Clustering instance setup with constant parameters, see
        `mosaic.Clustering` for available parameters.

    param_grid : dict
        Dictionary with parameters names (`str`) as keys and lists of
        parameter settings to try as values, or list of such dictionaries,
        in which case the grids spanned by each dictionary in the list are
        explored.

    gridsearch_kwargs : dict
        Dictionary with parameters to be used for
        [`sklearn.model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)
        class. The parameter `estimator` is not supported and `param_grid`
        needs to be passed directly to the class.


    Attributes
    ----------
    cv_results_ : dict of numpy (masked) ndarrays
        A dict with keys as column headers and values as columns.

    best_estimator_ : estimator
        Estimator that was chosen by the search, i.e. estimator
        which gave highest score (or smallest loss if specified)
        on the left out data.

    best_score_ : float
        Mean cross-validated score of the best_estimator.

    best_params_ : dict
        Parameter setting that gave the best results on the hold out data.

    best_index_ : int
        The index (of the `cv_results_` arrays) which corresponds to the best
        candidate parameter setting.

    n_splits_ : int
        The number of cross-validation splits (folds/iterations).

    Notes
    -----
    Check out
    [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)
    for an overview of all available attributes and more detailed description.

    Examples
    --------
    &gt;&gt;&gt; import mosaic
    &gt;&gt;&gt; # create two correlated data sets
    &gt;&gt;&gt; traj = np.array([
    ...     func(np.linspace(0, 20, 1000))
    ...     for  func in (
    ...         np.sin,
    ...         lambda x: np.sin(x + 0.1),
    ...         np.cos,
    ...         lambda x: np.cos(x + 0.1),
    ...     )
    ... ]).T
    &gt;&gt;&gt; search = mosaic.GridSearchCV(
    ...     similarity=mosaic.Similarity(),
    ...     clustering=mosaic.Clustering(),
    ...     param_grid={&#39;resolution_parameter&#39;: [0.05, 0.2]},
    ... )
    &gt;&gt;&gt; search.fit(traj)
    GridSearchCV(clustering=Clustering(),
                 param_grid={&#39;clust__resolution_parameter&#39;: [0.05, 0.2]},
                 similarity=Similarity())
    &gt;&gt;&gt; search.best_params_
    {&#39;clust__resolution_parameter&#39;: 0.2}
    &gt;&gt;&gt; search.best_estimator_
    Pipeline(steps=[(&#39;sim&#39;, Similarity()),
                    (&#39;clust&#39;, Clustering(resolution_parameter=0.2))])

    &#34;&#34;&#34;

    _sim_prefix: str = &#39;sim&#39;
    _clust_prefix: str = &#39;clust&#39;

    @beartype
    def __init__(
        self,
        *,
        similarity: Similarity,
        clustering: Clustering,
        param_grid: Dict,
        gridsearch_kwargs: Dict = {},
    ) -&gt; None:
        &#34;&#34;&#34;Initialize GridSearchCV class.&#34;&#34;&#34;
        self.similarity: Similarity = similarity
        self.clustering: Clustering = clustering
        self.gridsearch_kwargs: Dict = gridsearch_kwargs

        if &#39;estimator&#39; in self.gridsearch_kwargs:
            raise NotImplementedError(
                &#39;Custom estimators are not supported. Please use the &#39;
                &#39;sklearn class GirdSearchCV directly.&#39;,
            )

        if &#39;param_grid&#39; in self.gridsearch_kwargs:
            raise NotImplementedError(
                &#34;Please pass &#39;param_grid&#39; directly to the the class.&#34;,
            )

        if similarity.get_params()[&#39;low_memory&#39;]:
            raise NotImplementedError(
                &#34;&#39;low_memory&#39; is currently not implemented.&#34;,
            )

        if not param_grid:
            raise ValueError(
                &#39;At least a single parameter needs to be provided&#39;,
            )

        self.pipeline = Pipeline([
            (self._sim_prefix, self.similarity),
            (self._clust_prefix, self.clustering),
        ])

        self.param_grid: Dict = {}
        for param, values in param_grid.items():
            if param in similarity.get_params():
                self.param_grid[
                    f&#39;{self._sim_prefix}__{param}&#39;
                ] = values
            elif param in clustering.get_params():
                self.param_grid[
                    f&#39;{self._clust_prefix}__{param}&#39;
                ] = values
            else:
                raise ValueError(
                    f&#34;param_grid key &#39;{param}&#39; is not available.&#34;
                )

        super().__init__(
            estimator=self.pipeline,
            param_grid=self.param_grid,
            **self.gridsearch_kwargs,
        )

    @beartype
    def fit(
        self,
        X: FloatMax2DArray,
        y: Optional[np.ndarray] = None,
    ):
        &#34;&#34;&#34;Clusters the correlation matrix by Leiden clustering on a graph.

        Parameters
        ----------
        X : ndarray of shape (n_samples, n_features)
            Training vector, where `n_samples` is the number of samples and
            `n_features` is the number of features.

        y : Ignored
            Not used, present for scikit API consistency by convention.

        Returns
        -------
        self : object
            Fitted estimator.

        &#34;&#34;&#34;
        return super().fit(X)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.model_selection._search.GridSearchCV</li>
<li>sklearn.model_selection._search.BaseSearchCV</li>
<li>sklearn.base.MetaEstimatorMixin</li>
<li>sklearn.base.BaseEstimator</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mosaic.GridSearchCV.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, X, y=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Clusters the correlation matrix by Leiden clustering on a graph.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_samples, n_features)</code></dt>
<dd>Training vector, where <code>n_samples</code> is the number of samples and
<code>n_features</code> is the number of features.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>Ignored</code></dt>
<dd>Not used, present for scikit API consistency by convention.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>self</code></strong> :&ensp;<code>object</code></dt>
<dd>Fitted estimator.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def fit(
    self,
    X: FloatMax2DArray,
    y: Optional[np.ndarray] = None,
):
    &#34;&#34;&#34;Clusters the correlation matrix by Leiden clustering on a graph.

    Parameters
    ----------
    X : ndarray of shape (n_samples, n_features)
        Training vector, where `n_samples` is the number of samples and
        `n_features` is the number of features.

    y : Ignored
        Not used, present for scikit API consistency by convention.

    Returns
    -------
    self : object
        Fitted estimator.

    &#34;&#34;&#34;
    return super().fit(X)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mosaic.Similarity"><code class="flex name class">
<span>class <span class="ident">Similarity</span></span>
<span>(</span><span>*, metric='correlation', low_memory=False, normalize_method=None, use_knn_estimator=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for calculating the similarity measure.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>metric</code></strong> :&ensp;<code>str</code>, default=<code>'correlation'</code></dt>
<dd>
<p>the correlation metric to use for the feature distance matrix.</p>
<ul>
<li><code>'correlation'</code> will use the absolute value of the Pearson
correlation</li>
<li><code>'NMI'</code> will use the mutual information normalized by joined entropy</li>
<li><code>'GY'</code> uses Gel'fand and Yaglom normalization<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup></li>
<li><code>'JSD'</code> will use the Jensen-Shannon divergence between the joint
probability distribution and the product of the marginal probability
distributions to calculate their dissimilarity</li>
</ul>
<p>Note: <code>'NMI'</code> is supported only with low_memory=False</p>
</dd>
<dt><strong><code>low_memory</code></strong> :&ensp;<code>bool</code>, default=<code>False</code></dt>
<dd>If True, the input of fit X needs to be a file name and the correlation
is calculated on the fly. Otherwise, an array is assumed as input X.</dd>
<dt><strong><code>normalize_method</code></strong> :&ensp;<code>str</code>, default=<code>'geometric'</code></dt>
<dd>
<p>Only required for metric <code>'NMI'</code>. Determines the normalization factor
for the mutual information:</p>
<ul>
<li><code>'joint'</code> is the joint entropy</li>
<li><code>'max'</code> is the maximum of the individual entropies</li>
<li><code>'arithmetic'</code> is the mean of the individual entropies</li>
<li><code>'geometric'</code> is the square root of the product of the individual
entropies</li>
<li><code>'min'</code> is the minimum of the individual entropies</li>
</ul>
</dd>
<dt><strong><code>use_knn_estimator</code></strong> :&ensp;<code>bool</code>, default=<code>False</code></dt>
<dd>Can only be set for metric GY. If True, the mutual information
is estimated reliably by a parameter free method based on entropy
estimation from k-nearest neighbors distances<sup id="fnref:3"><a class="footnote-ref" href="#fn:3">3</a></sup>.
It considerably increases the computational time and is thus
only advisable for relatively small data-sets.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>matrix_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features, n_features)</code></dt>
<dd>The correlation-measure-based pairwise distance matrix of the data. It
scales from [0, 1].</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import mosaic
&gt;&gt;&gt; x = np.linspace(0, np.pi, 1000)
&gt;&gt;&gt; data = np.array([np.cos(x), np.cos(x + np.pi / 6)]).T
&gt;&gt;&gt; sim = mosaic.Similarity()
&gt;&gt;&gt; sim.fit(data)
Similarity()
&gt;&gt;&gt; sim.matrix_
array([[1.       , 0.9697832],
       [0.9697832, 1.       ]])
</code></pre>
<h2 id="notes">Notes</h2>
<p>The correlation is defined as
<span><span class="MathJax_Preview">\rho_{X,Y} =
\frac{\langle(X -\mu_X)(Y -\mu_Y)\rangle}{\sigma_X\sigma_Y}</span><script type="math/tex; mode=display">\rho_{X,Y} =
\frac{\langle(X -\mu_X)(Y -\mu_Y)\rangle}{\sigma_X\sigma_Y}</script></span>
where for the online (low memory) algorithm the Welford algorithm taken
from Donald E. Knuth were used <sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup>.</p>
<p>The Jensen-Shannon divergence is defined as
<span><span class="MathJax_Preview">D_{\text{JS}} = \frac{1}{2} D_{\text{KL}}(p(x,y)||M)
+ \frac{1}{2} D_{\text{KL}}(p(x)p(y)||M)\;,</span><script type="math/tex; mode=display">D_{\text{JS}} = \frac{1}{2} D_{\text{KL}}(p(x,y)||M)
+ \frac{1}{2} D_{\text{KL}}(p(x)p(y)||M)\;,</script></span>
where <span><span class="MathJax_Preview">M = \frac{1}{2} [p(x,y) + p(x)p(y)]</span><script type="math/tex">M = \frac{1}{2} [p(x,y) + p(x)p(y)]</script></span> is an averaged probability
distribution and <span><span class="MathJax_Preview">D_{\text{KL}}</span><script type="math/tex">D_{\text{KL}}</script></span> denotes the Kullback-Leibler divergence.</p>
<p>Initialize Similarity class.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:1">
<p>Gel'fand, I.M. and Yaglom, A.M. (1957). "Calculation of amount of
information about a random function contained in another such
function".
American Mathematical Society Translations, series 2, 12, pp. 199–246.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p>Welford algorithm, generalized to correlation. Taken from:
Donald E. Knuth (1998). "The Art of Computer Programming", volume 2:
Seminumerical Algorithms, 3rd edn., p. 232. Boston: Addison-Wesley.&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:3">
<p>B.C. Ross, PLoS ONE 9(2) (2014), "Mutual Information between Discrete
and Continuous Data Sets"&#160;<a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
</ol>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Similarity(BaseEstimator):
    r&#34;&#34;&#34;Class for calculating the similarity measure.

    Parameters
    ----------
    metric : str, default=&#39;correlation&#39;
        the correlation metric to use for the feature distance matrix.

        - `&#39;correlation&#39;` will use the absolute value of the Pearson
          correlation
        - `&#39;NMI&#39;` will use the mutual information normalized by joined entropy
        - `&#39;GY&#39;` uses Gel&#39;fand and Yaglom normalization[^1]
        - `&#39;JSD&#39;` will use the Jensen-Shannon divergence between the joint
          probability distribution and the product of the marginal probability
          distributions to calculate their dissimilarity

        Note: `&#39;NMI&#39;` is supported only with low_memory=False

    low_memory : bool, default=False
        If True, the input of fit X needs to be a file name and the correlation
        is calculated on the fly. Otherwise, an array is assumed as input X.

    normalize_method : str, default=&#39;geometric&#39;
        Only required for metric `&#39;NMI&#39;`. Determines the normalization factor
        for the mutual information:

        - `&#39;joint&#39;` is the joint entropy
        - `&#39;max&#39;` is the maximum of the individual entropies
        - `&#39;arithmetic&#39;` is the mean of the individual entropies
        - `&#39;geometric&#39;` is the square root of the product of the individual
          entropies
        - `&#39;min&#39;` is the minimum of the individual entropies

    use_knn_estimator : bool, default=False
        Can only be set for metric GY. If True, the mutual information
        is estimated reliably by a parameter free method based on entropy
        estimation from k-nearest neighbors distances[^3].
        It considerably increases the computational time and is thus
        only advisable for relatively small data-sets.

    Attributes
    ----------
    matrix_ : ndarray of shape (n_features, n_features)
        The correlation-measure-based pairwise distance matrix of the data. It
        scales from [0, 1].

    Examples
    --------
    &gt;&gt;&gt; import mosaic
    &gt;&gt;&gt; x = np.linspace(0, np.pi, 1000)
    &gt;&gt;&gt; data = np.array([np.cos(x), np.cos(x + np.pi / 6)]).T
    &gt;&gt;&gt; sim = mosaic.Similarity()
    &gt;&gt;&gt; sim.fit(data)
    Similarity()
    &gt;&gt;&gt; sim.matrix_
    array([[1.       , 0.9697832],
           [0.9697832, 1.       ]])


    Notes
    -----
    The correlation is defined as
    $$\rho_{X,Y} =
    \frac{\langle(X -\mu_X)(Y -\mu_Y)\rangle}{\sigma_X\sigma_Y}$$
    where for the online (low memory) algorithm the Welford algorithm taken
    from Donald E. Knuth were used [^2].

    [^1]: Gel&#39;fand, I.M. and Yaglom, A.M. (1957). &#34;Calculation of amount of
        information about a random function contained in another such
        function&#34;.
        American Mathematical Society Translations, series 2, 12, pp. 199–246.

    [^2]: Welford algorithm, generalized to correlation. Taken from:
        Donald E. Knuth (1998). &#34;The Art of Computer Programming&#34;, volume 2:
        Seminumerical Algorithms, 3rd edn., p. 232. Boston: Addison-Wesley.

    [^3]: B.C. Ross, PLoS ONE 9(2) (2014), &#34;Mutual Information between Discrete
        and Continuous Data Sets&#34;

    The Jensen-Shannon divergence is defined as
    $$D_{\text{JS}} = \frac{1}{2} D_{\text{KL}}(p(x,y)||M)
    + \frac{1}{2} D_{\text{KL}}(p(x)p(y)||M)\;,$$
    where \(M = \frac{1}{2} [p(x,y) + p(x)p(y)]\) is an averaged probability
    distribution and \(D_{\text{KL}}\) denotes the Kullback-Leibler divergence.

    &#34;&#34;&#34;

    _dtype: np.dtype = np.float64
    _default_normalize_method: str = &#39;geometric&#39;

    @beartype
    def __init__(
        self,
        *,
        metric: MetricString = &#39;correlation&#39;,
        low_memory: bool = False,
        normalize_method: Optional[NormString] = None,
        use_knn_estimator: bool = False,
    ):
        &#34;&#34;&#34;Initialize Similarity class.&#34;&#34;&#34;
        self.metric: MetricString = metric
        self.low_memory: bool = low_memory
        self.use_knn_estimator: bool = use_knn_estimator
        if self.metric == &#39;NMI&#39;:
            if normalize_method is None:
                normalize_method = self._default_normalize_method
        elif normalize_method is not None:
            raise NotImplementedError(
                &#39;Normalize methods are only supported with metric=&#34;NMI&#34;&#39;,
            )
        self.normalize_method: NormString = normalize_method
        if self.metric != &#39;GY&#39; and self.use_knn_estimator:
            raise NotImplementedError(
                (
                    &#39;The mutual information estimate based on k-nearest&#39;
                    &#39;neighbors distances is only supported with metric=&#34;GY&#34;&#39;
                ),
            )

    @singledispatchmethod
    @beartype
    def fit(
        self,
        X: Union[FloatMax2DArray, str],
        y: Optional[ArrayLikeFloat] = None,
    ):
        &#34;&#34;&#34;Compute the correlation/nmi distance matrix.

        Parameters
        ----------
        X : ndarray of shape (n_samples, n_features) or str if low_memory=True
            Training data.

        y : Ignored
            Not used, present for scikit API consistency by convention.

        Returns
        -------
        self : object
            Fitted estimator.

        &#34;&#34;&#34;
        raise NotImplementedError(&#39;Fatal error, this should never be reached.&#39;)

    @fit.register
    def _(self, X: np.ndarray, y=None):
        &#34;&#34;&#34;Dispatched for low_memory=False with matrix input.&#34;&#34;&#34;
        self._reset()

        corr: np.ndarray
        matrix_: np.ndarray
        # parse data
        if self.low_memory:
            raise TypeError(&#39;Using low_memory=True requires X:str&#39;)
        if X.ndim == 1:
            raise ValueError(
                &#39;Reshape your data either using array.reshape(-1, 1) if your &#39;
                &#39;data has a single feature or array.reshape(1, -1) if it &#39;
                &#39;contains a single sample.&#39;,
            )

        n_samples, n_features = X.shape
        self._n_samples: int = n_samples
        self._n_features: int = n_features

        X: np.ndarray = _standard_scaler(X)
        if self.metric == &#39;correlation&#39;:
            corr = _correlation(X)
            matrix_ = np.abs(corr)
        elif self.metric == &#39;GY&#39; and self.use_knn_estimator:
            matrix_ = _nonlinear_GY_knn(X)
        else:  # &#39;NMI&#39;, &#39;JSD&#39;, &#39;GY
            matrix_ = self._nonlinear_correlation(X)
        self.matrix_: np.ndarray = np.clip(matrix_, a_min=0, a_max=1)

        return self

    @fit.register
    def _(self, X: str, y=None):
        &#34;&#34;&#34;Dispatched for low_memory=True with string.&#34;&#34;&#34;
        self._reset()

        corr: np.ndarray
        matrix_: np.ndarray
        # parse data
        if not self.low_memory:
            raise TypeError(&#39;Mode low_memory=False reuqires X:np.ndarray.&#39;)

        if self.metric == &#39;correlation&#39;:
            corr = self._online_correlation(X)
            matrix_ = np.abs(corr)
        else:
            raise NotImplementedError(
                &#39;Mode low_memory=True is only implemented for correlation.&#39;,
            )

        self.matrix_: np.ndarray = np.clip(matrix_, a_min=0, a_max=1)

        return self

    @beartype
    def fit_transform(
        self,
        X: Union[FloatMax2DArray, str],
        y: Optional[ArrayLikeFloat] = None,
    ) -&gt; FloatMatrix:
        &#34;&#34;&#34;Compute the correlation/nmi distance matrix and returns it.

        Parameters
        ----------
        X : ndarray of shape (n_samples, n_features) or str if low_memory=True
            Training data.

        y : Ignored
            Not used, present for scikit API consistency by convention.

        Returns
        -------
        Similarity : ndarray of shape (n_features, n_features)
            Similarity matrix.

        &#34;&#34;&#34;
        self.fit(X)
        return self.matrix_

    @beartype
    def transform(
        self,
        X: Union[FloatMax2DArray, str],
    ) -&gt; FloatMatrix:
        &#34;&#34;&#34;Compute the correlation/nmi distance matrix and returns it.

        Parameters
        ----------
        X : ndarray of shape (n_samples, n_features) or str if low_memory=True
            Training data.

        Returns
        -------
        Similarity : ndarray of shape (n_features, n_features)
            Similarity matrix.

        &#34;&#34;&#34;
        return self.fit_transform(X)

    @beartype
    def _reset(self) -&gt; None:
        &#34;&#34;&#34;Reset internal data-dependent state of correlation.&#34;&#34;&#34;
        if hasattr(self, &#39;matrix_&#39;):  # noqa: WPS421
            del self.matrix_  # noqa: WPS420

    @beartype
    def _nonlinear_correlation(self, X: Float2DArray) -&gt; FloatMatrix:
        &#34;&#34;&#34;Return the nonlinear correlation.&#34;&#34;&#34;
        calc_nl_corr: Callable
        if self.metric == &#39;NMI&#39;:
            calc_nl_corr = _nmi_gen(self.normalize_method)
        elif self.metric == &#39;GY&#39;:
            calc_nl_corr = _gy
        else:
            calc_nl_corr = _jsd

        nl_corr: FloatMatrix = np.empty(  # noqa: WPS317
            (self._n_features, self._n_features), dtype=self._dtype,
        )
        for idx_i, xi in enumerate(X.T):
            nl_corr[idx_i, idx_i] = 1
            for idx_j, xj in enumerate(X.T[idx_i + 1:], idx_i + 1):
                nl_corr_ij = calc_nl_corr(*_estimate_densities(xi, xj))
                nl_corr[idx_i, idx_j] = nl_corr_ij
                nl_corr[idx_j, idx_i] = nl_corr_ij

        return nl_corr

    @beartype
    def _online_correlation(self, X: str) -&gt; FloatMatrix:
        &#34;&#34;&#34;Calculate correlation on the fly.&#34;&#34;&#34;
        self._filename: str = X

        corr, n_samples, n_features = _welford_correlation(
            filename=self._filename,
            dtype=self._dtype,
        )
        self._n_samples: int = n_samples
        self._n_features: int = n_features
        return corr</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.base.BaseEstimator</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mosaic.Similarity.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, X, y=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the correlation/nmi distance matrix.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_samples, n_features)</code> or <code>str if low_memory=True</code></dt>
<dd>Training data.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>Ignored</code></dt>
<dd>Not used, present for scikit API consistency by convention.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>self</code></strong> :&ensp;<code>object</code></dt>
<dd>Fitted estimator.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@singledispatchmethod
@beartype
def fit(
    self,
    X: Union[FloatMax2DArray, str],
    y: Optional[ArrayLikeFloat] = None,
):
    &#34;&#34;&#34;Compute the correlation/nmi distance matrix.

    Parameters
    ----------
    X : ndarray of shape (n_samples, n_features) or str if low_memory=True
        Training data.

    y : Ignored
        Not used, present for scikit API consistency by convention.

    Returns
    -------
    self : object
        Fitted estimator.

    &#34;&#34;&#34;
    raise NotImplementedError(&#39;Fatal error, this should never be reached.&#39;)</code></pre>
</details>
</dd>
<dt id="mosaic.Similarity.fit_transform"><code class="name flex">
<span>def <span class="ident">fit_transform</span></span>(<span>self, X, y=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the correlation/nmi distance matrix and returns it.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_samples, n_features)</code> or <code>str if low_memory=True</code></dt>
<dd>Training data.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>Ignored</code></dt>
<dd>Not used, present for scikit API consistency by convention.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>Similarity</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features, n_features)</code></dt>
<dd>Similarity matrix.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def fit_transform(
    self,
    X: Union[FloatMax2DArray, str],
    y: Optional[ArrayLikeFloat] = None,
) -&gt; FloatMatrix:
    &#34;&#34;&#34;Compute the correlation/nmi distance matrix and returns it.

    Parameters
    ----------
    X : ndarray of shape (n_samples, n_features) or str if low_memory=True
        Training data.

    y : Ignored
        Not used, present for scikit API consistency by convention.

    Returns
    -------
    Similarity : ndarray of shape (n_features, n_features)
        Similarity matrix.

    &#34;&#34;&#34;
    self.fit(X)
    return self.matrix_</code></pre>
</details>
</dd>
<dt id="mosaic.Similarity.transform"><code class="name flex">
<span>def <span class="ident">transform</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the correlation/nmi distance matrix and returns it.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_samples, n_features)</code> or <code>str if low_memory=True</code></dt>
<dd>Training data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>Similarity</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features, n_features)</code></dt>
<dd>Similarity matrix.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def transform(
    self,
    X: Union[FloatMax2DArray, str],
) -&gt; FloatMatrix:
    &#34;&#34;&#34;Compute the correlation/nmi distance matrix and returns it.

    Parameters
    ----------
    X : ndarray of shape (n_samples, n_features) or str if low_memory=True
        Training data.

    Returns
    -------
    Similarity : ndarray of shape (n_features, n_features)
        Similarity matrix.

    &#34;&#34;&#34;
    return self.fit_transform(X)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mosaic.UMAPSimilarity"><code class="flex name class">
<span>class <span class="ident">UMAPSimilarity</span></span>
<span>(</span><span>*, densmap=True, n_neighbors=None, n_components=2)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for embedding similarity matrix with UMAP.</p>
<p>For more details on the parameters check the UMAP documentation.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>densmap</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>If True the density-augmented objective of densMAP is used for
optimization. There the local densities are encouraged to be correlated
with those in the original space.</dd>
<dt><strong><code>n_neighbors</code></strong> :&ensp;<code>int</code>, default=<code>None</code></dt>
<dd>Size of nearest neighbors used for manifold estimation in UMAP.
If <code>None</code> uses square root of the number of features.</dd>
<dt><strong><code>n_components</code></strong> :&ensp;<code>int</code>, default=<code>2</code></dt>
<dd>Dimensionality of the local embedding.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>matrix_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features, n_features)</code></dt>
<dd>Normalized pairwise distance matrix of the UMAP embedding.</dd>
<dt><strong><code>embedding_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features, n_components)</code></dt>
<dd>Coordinates of features in UMAP embedding.</dd>
<dt><strong><code>n_neighbors_</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of used neighbors.</dd>
</dl>
<p>Initialize UMAPSimilarity class.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class UMAPSimilarity:  # noqa: WPS214
    r&#34;&#34;&#34;Class for embedding similarity matrix with UMAP.

    For more details on the parameters check the UMAP documentation.

    Parameters
    ----------
    densmap : bool, default=True
        If True the density-augmented objective of densMAP is used for
        optimization. There the local densities are encouraged to be correlated
        with those in the original space.

    n_neighbors: int, default=None
        Size of nearest neighbors used for manifold estimation in UMAP.
        If `None` uses square root of the number of features.

    n_components: int, default=2
        Dimensionality of the local embedding.

    Attributes
    ----------
    matrix_ : ndarray of shape (n_features, n_features)
        Normalized pairwise distance matrix of the UMAP embedding.

    embedding_ : ndarray of shape (n_features, n_components)
        Coordinates of features in UMAP embedding.

    n_neighbors_ : int
        Number of used neighbors.

    &#34;&#34;&#34;

    _default_n_components: PositiveInt = 2

    @beartype
    def __init__(
        self,
        *,
        densmap: bool = True,
        n_neighbors: Optional[PositiveInt] = None,
        n_components: PositiveInt = _default_n_components,
    ):
        &#34;&#34;&#34;Initialize UMAPSimilarity class.&#34;&#34;&#34;
        # import optinal dependency umap.
        self._umap = _importUmap()

        self._densmap: bool = densmap
        self._n_neighbors: Optional[PositiveInt] = n_neighbors
        self._n_components: PositiveInt = n_components

    @beartype
    def fit(
        self,
        X: Float2DArray,
        y: Optional[ArrayLikeFloat] = None,
    ) -&gt; None:
        &#34;&#34;&#34;Fit similarity matrix into UMAP embedding.&#34;&#34;&#34;
        self._reset()

        # parse data
        self._n_features: int = X.shape[0]

        # parse n_neighbors
        if self._n_neighbors is None:
            self._n_neighbors = np.ceil(np.sqrt(self._n_features)).astype(int)
        elif self._n_neighbors &gt;= len(X):
            raise ValueError(
                &#39;The number of nearest neighbors must be smaller than the &#39;
                &#39;number of features.&#39;,
            )
        self.n_neighbors_: PositiveInt = self._n_neighbors

        reducer = self._umap.UMAP(
            n_neighbors=self._n_neighbors,
            densmap=self._densmap,
            n_components=self._n_components,
            metric=&#39;precomputed&#39;,
        )

        # run UMAP with dissimalirty matrix
        with warnings.catch_warnings():
            warnings.filterwarnings(
                &#39;ignore&#39;,
                message=&#39;using precomputed metric&#39;,
            )
            embedding: np.ndarray = reducer.fit_transform(1 - X)
        matrix_: np.ndarray = _calc_distance_matrix(embedding)

        self.embedding_: np.ndarray = embedding
        self.matrix_: np.ndarray = 1 - matrix_ / np.nanmax(matrix_)

    @beartype
    def _reset(self) -&gt; None:
        &#34;&#34;&#34;Reset internal data-dependent state of correlation.&#34;&#34;&#34;
        if hasattr(self, &#39;matrix_&#39;):  # noqa: WPS421
            del self.matrix_  # noqa: WPS420</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="mosaic.UMAPSimilarity.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, X, y=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Fit similarity matrix into UMAP embedding.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def fit(
    self,
    X: Float2DArray,
    y: Optional[ArrayLikeFloat] = None,
) -&gt; None:
    &#34;&#34;&#34;Fit similarity matrix into UMAP embedding.&#34;&#34;&#34;
    self._reset()

    # parse data
    self._n_features: int = X.shape[0]

    # parse n_neighbors
    if self._n_neighbors is None:
        self._n_neighbors = np.ceil(np.sqrt(self._n_features)).astype(int)
    elif self._n_neighbors &gt;= len(X):
        raise ValueError(
            &#39;The number of nearest neighbors must be smaller than the &#39;
            &#39;number of features.&#39;,
        )
    self.n_neighbors_: PositiveInt = self._n_neighbors

    reducer = self._umap.UMAP(
        n_neighbors=self._n_neighbors,
        densmap=self._densmap,
        n_components=self._n_components,
        metric=&#39;precomputed&#39;,
    )

    # run UMAP with dissimalirty matrix
    with warnings.catch_warnings():
        warnings.filterwarnings(
            &#39;ignore&#39;,
            message=&#39;using precomputed metric&#39;,
        )
        embedding: np.ndarray = reducer.fit_transform(1 - X)
    matrix_: np.ndarray = _calc_distance_matrix(embedding)

    self.embedding_: np.ndarray = embedding
    self.matrix_: np.ndarray = 1 - matrix_ / np.nanmax(matrix_)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="MoSAIC home" href="https://moldyn.github.io/MoSAIC">
<img src="logo_large_light.svg" style="width: 200px;" class="lightmode" alt="">
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#molecular-systems-automated-identification-of-cooperativity">Molecular Systems Automated Identification of Cooperativity</a><ul>
<li><a href="#features">Features</a></li>
<li><a href="#installation">Installation</a><ul>
<li><a href="#shell-completion">Shell Completion</a></li>
</ul>
</li>
<li><a href="#usage">Usage</a><ul>
<li><a href="#ci-usage-directly-from-the-command-line">CI - Usage Directly from the Command Line</a></li>
<li><a href="#module-inside-a-python-script">Module - Inside a Python Script</a></li>
<li><a href="#cross-validation-of-parameters">Cross-Validation of Parameters</a></li>
<li><a href="#faq">FAQ</a><ul>
<li><a href="#how-to-load-the-clusters-file-back-to-python">How to load the clusters file back to Python?</a></li>
<li><a href="#is-it-possible-to-use-cross-validation-together-with-silhouette-score">Is it possible to use cross validation together with silhouette score?</a></li>
<li><a href="#i-get-an-error">I get an error.</a></li>
<li><a href="#should-i-upgrade-the-package">Should I upgrade the package?</a></li>
<li><a href="#how-can-i-interpretate-the-results">How can I interpretate the results?</a></li>
<li><a href="#is-it-possible-to-install-the-cli-only">Is it possible to install the CLI only?</a></li>
<li><a href="#is-the-silhouette-method-implemented">Is the silhouette method implemented?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="mosaic.clustering" href="clustering.html">mosaic.clustering</a></code></li>
<li><code><a title="mosaic.gridsearch" href="gridsearch.html">mosaic.gridsearch</a></code></li>
<li><code><a title="mosaic.similarity" href="similarity.html">mosaic.similarity</a></code></li>
<li><code><a title="mosaic.umap_similarity" href="umap_similarity.html">mosaic.umap_similarity</a></code></li>
<li><code><a title="mosaic.utils" href="utils.html">mosaic.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="mosaic.Clustering" href="#mosaic.Clustering">Clustering</a></code></h4>
<ul class="">
<li><code><a title="mosaic.Clustering.fit" href="#mosaic.Clustering.fit">fit</a></code></li>
<li><code><a title="mosaic.Clustering.fit_predict" href="#mosaic.Clustering.fit_predict">fit_predict</a></code></li>
<li><code><a title="mosaic.Clustering.score" href="#mosaic.Clustering.score">score</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mosaic.GridSearchCV" href="#mosaic.GridSearchCV">GridSearchCV</a></code></h4>
<ul class="">
<li><code><a title="mosaic.GridSearchCV.fit" href="#mosaic.GridSearchCV.fit">fit</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mosaic.Similarity" href="#mosaic.Similarity">Similarity</a></code></h4>
<ul class="">
<li><code><a title="mosaic.Similarity.fit" href="#mosaic.Similarity.fit">fit</a></code></li>
<li><code><a title="mosaic.Similarity.fit_transform" href="#mosaic.Similarity.fit_transform">fit_transform</a></code></li>
<li><code><a title="mosaic.Similarity.transform" href="#mosaic.Similarity.transform">transform</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mosaic.UMAPSimilarity" href="#mosaic.UMAPSimilarity">UMAPSimilarity</a></code></h4>
<ul class="">
<li><code><a title="mosaic.UMAPSimilarity.fit" href="#mosaic.UMAPSimilarity.fit">fit</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<a href="https://github.com/moldyn/MoSAIC" class="github-corner" aria-label="View source on GitHub">
<svg width="80" height="80" viewBox="0 0 250 250" style="fill:#4d4f53; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true">
<path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
<path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
<path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path>
</svg>
</a>
<style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>